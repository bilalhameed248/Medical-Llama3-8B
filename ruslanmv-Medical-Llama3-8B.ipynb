{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "085eec06",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4bc2b82-dfe0-42e3-95e8-a354f7755eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 10:49:02.691390: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-05 10:49:02.743167: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-05 10:49:03.458233: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b3d63a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os, evaluate, torch, accelerate, nltk, re, datetime \n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import BertTokenizer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import AutoModelForTokenClassification, AutoModelForCausalLM\n",
    "from datasets import load_metric\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from pynvml import *\n",
    "from numba import cuda\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c9835c",
   "metadata": {},
   "source": [
    "## Get Current Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01756186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /home/sharjeelahmed/datascience/\n"
     ]
    }
   ],
   "source": [
    "my_dir = os.getcwd() + '/' \n",
    "print(f\"CWD: {my_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2833e0b",
   "metadata": {},
   "source": [
    "## GPU Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3b562",
   "metadata": {},
   "source": [
    "<p> Reset Cuda Memory</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45ce30da",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m device\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/datascience/gpu_env/lib/python3.8/site-packages/torch/cuda/memory.py:162\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ec71aa",
   "metadata": {},
   "source": [
    "<p>Check GPU Memory</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e36552e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total    : 15360 MB\n",
      "Free     : 14490 MB\n",
      "Used     : 869 MB\n"
     ]
    }
   ],
   "source": [
    "nvmlInit()\n",
    "h = nvmlDeviceGetHandleByIndex(0)\n",
    "info = nvmlDeviceGetMemoryInfo(h)\n",
    "print(f'Total    : {info.total//1024**2} MB')\n",
    "print(f'Free     : {info.free//1024**2} MB')\n",
    "print(f'Used     : {info.used//1024**2} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ab82b5",
   "metadata": {},
   "source": [
    "### Get Cuda Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6196c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "devices = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1051af75",
   "metadata": {},
   "source": [
    "## Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "551b3d93-b2b5-460d-bbcb-0828903d7ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ruslanmv/Medical-Llama3-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e03d76d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7b1f0db32b4cdcb8648520c02e9e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre_trained_model = AutoModelForCausalLM.from_pretrained(\"ruslanmv/Medical-Llama3-8B\").to(devices)  # If using GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940fdfe1-6a16-4341-9510-74147c12c0d3",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c5d2c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! I'm here to help. Let's start by discussing your symptoms. \n",
      "\n",
      "    Fatigue: This could be a sign of several conditions, including dengue. However, it's important to note that fatigue can also be caused by other factors, such as stress, lack of sleep, or an underlying medical condition. \n",
      "\n",
      "    Increased sensitivity to cold: This could be a sign of dengue, as it's a common symptom of the disease. However, it's important to note that this symptom can also be caused by other factors, such as anemia or hypothyroidism. \n",
      "\n",
      "    Dry, itchy skin: This could be a sign of dengue, as it's a common symptom of the disease. However, it's important to note that this symptom can also be caused by other factors, such as eczema or psoriasis. \n",
      "\n",
      "    Based on your symptoms, it's possible that you may have dengue. However, it's important to note that these symptoms can also be caused by other factors. It's always best to consult with a healthcare professional to determine the underlying cause of your symptoms. \n",
      "\n",
      "    If you suspect that you may have dengue, it's important to seek medical attention immediately. Dengue can be a serious illness, and prompt treatment is crucial to prevent complications. \n",
      "\n",
      "    I hope this information is helpful. Please don't hesitate to ask any further questions you may have. \n",
      "\n",
      "    <|im_end|\n"
     ]
    }
   ],
   "source": [
    "def askme(question):\n",
    "    sys_message = ''' \n",
    "    You are an AI Medical Assistant trained on a vast dataset of health information. Please be thorough and\n",
    "    provide an informative answer. If you don't know the answer to a specific medical inquiry, advise seeking professional help.\n",
    "    '''\n",
    "    \n",
    "    # Create messages structured for the chat template\n",
    "    messages = [{\"role\": \"system\", \"content\": sys_message}, {\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "    # Applying chat template\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(devices)\n",
    "    outputs = pre_trained_model.generate(**inputs, max_new_tokens=300, use_cache=True)  # Adjust max_new_tokens for longer responses\n",
    "\n",
    "    # Extract and return the generated text\n",
    "    answer = tokenizer.batch_decode(outputs)[0].strip()\n",
    "    answer = answer.replace(sys_message, \"\").replace(question, \"\")\n",
    "    answer = answer.split(\"assistant\")[-1].strip()\n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "# - Context: First describe your problem.\n",
    "# - Question: Then make the question.\n",
    "question = '''\n",
    "I'm a 35-year-old male and for the past few months, I've been experiencing fatigue, increased sensitivity to cold, and dry, itchy skin.  \n",
    "\n",
    "Could these symptoms be related to dengue? \n",
    "'''\n",
    "result = askme(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a33ccdd-38c6-4bd6-a2b2-d75e10a6e797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9171d555-882d-4b74-ac53-a067e1e0f54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df71a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
